{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 4. 웹 스크레이핑을 사용한 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>업종</th>\n",
       "      <th>주요제품</th>\n",
       "      <th>상장일</th>\n",
       "      <th>결산월</th>\n",
       "      <th>대표자명</th>\n",
       "      <th>홈페이지</th>\n",
       "      <th>지역</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>마녀공장</td>\n",
       "      <td>439090</td>\n",
       "      <td>기타 화학제품 제조업</td>\n",
       "      <td>자연주의 기능성 화장품</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>12월</td>\n",
       "      <td>유근직</td>\n",
       "      <td>http://www.manyo.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나라셀라</td>\n",
       "      <td>405920</td>\n",
       "      <td>음·식료품 및 담배 도매업</td>\n",
       "      <td>와인 도소매</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>12월</td>\n",
       "      <td>마승철</td>\n",
       "      <td>http://www.naracellar.com/</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>진영</td>\n",
       "      <td>285800</td>\n",
       "      <td>플라스틱제품 제조업</td>\n",
       "      <td>가구용 ASA플라스틱 시트, 엣지밴드</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>12월</td>\n",
       "      <td>심영수</td>\n",
       "      <td>http://www.jyp21.co.kr</td>\n",
       "      <td>인천광역시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이수스페셜티케미컬</td>\n",
       "      <td>457190</td>\n",
       "      <td>기초 화학물질 제조업</td>\n",
       "      <td>석유화학제품 및 정밀화학제품</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>12월</td>\n",
       "      <td>류승호</td>\n",
       "      <td>http://www.isuspecialtychemical.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCI</td>\n",
       "      <td>456040</td>\n",
       "      <td>기초 화학물질 제조업</td>\n",
       "      <td>폴리실리콘,타르제품,카본블랙,무수프탈산,농약원제,석탄화학제품,정밀화학제품,플라스틱창...</td>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>12월</td>\n",
       "      <td>김택중, 김유신</td>\n",
       "      <td>NaN</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>유한양행</td>\n",
       "      <td>100</td>\n",
       "      <td>의약품 제조업</td>\n",
       "      <td>의약품(삐콤씨, 안티푸라민, 렉라자, 로수바미브, 코푸시럽 등), 생활용품(유한락스...</td>\n",
       "      <td>1962-11-01</td>\n",
       "      <td>12월</td>\n",
       "      <td>대표이사 조욱제</td>\n",
       "      <td>http://www.yuhan.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>120</td>\n",
       "      <td>도로 화물 운송업</td>\n",
       "      <td>Contract Logistics, 포워딩, 항만하역, 해운, 택배국제특송, SCM...</td>\n",
       "      <td>1956-07-02</td>\n",
       "      <td>12월</td>\n",
       "      <td>강신호,민영학(각자대표)</td>\n",
       "      <td>http://www.cjlogistics.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>경방</td>\n",
       "      <td>50</td>\n",
       "      <td>종합 소매업</td>\n",
       "      <td>섬유류(면사,면혼방사,면직물,면혼방직물,화섬사,화섬직물) 제조,도매,수출입</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>김준, 김담</td>\n",
       "      <td>http://www.kyungbang.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>유수홀딩스</td>\n",
       "      <td>700</td>\n",
       "      <td>회사 본부 및 경영 컨설팅 서비스업</td>\n",
       "      <td>지주사업</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>송영규</td>\n",
       "      <td>http://www.eusu-holdings.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>한진중공업홀딩스</td>\n",
       "      <td>3480</td>\n",
       "      <td>연료용 가스 제조 및 배관공급업</td>\n",
       "      <td>지주회사</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>조남호, 조원국</td>\n",
       "      <td>http://www.hhic-holdings.com</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2599 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명    종목코드                   업종   \n",
       "0          마녀공장  439090          기타 화학제품 제조업  \\\n",
       "1          나라셀라  405920       음·식료품 및 담배 도매업   \n",
       "2            진영  285800           플라스틱제품 제조업   \n",
       "3     이수스페셜티케미컬  457190          기초 화학물질 제조업   \n",
       "4           OCI  456040          기초 화학물질 제조업   \n",
       "...         ...     ...                  ...   \n",
       "2594       유한양행     100              의약품 제조업   \n",
       "2595     CJ대한통운     120            도로 화물 운송업   \n",
       "2596         경방      50               종합 소매업   \n",
       "2597      유수홀딩스     700  회사 본부 및 경영 컨설팅 서비스업   \n",
       "2598   한진중공업홀딩스    3480    연료용 가스 제조 및 배관공급업   \n",
       "\n",
       "                                                   주요제품         상장일  결산월   \n",
       "0                                          자연주의 기능성 화장품  2023-06-08  12월  \\\n",
       "1                                                와인 도소매  2023-06-02  12월   \n",
       "2                                  가구용 ASA플라스틱 시트, 엣지밴드  2023-06-01  12월   \n",
       "3                                       석유화학제품 및 정밀화학제품  2023-05-31  12월   \n",
       "4     폴리실리콘,타르제품,카본블랙,무수프탈산,농약원제,석탄화학제품,정밀화학제품,플라스틱창...  2023-05-30  12월   \n",
       "...                                                 ...         ...  ...   \n",
       "2594  의약품(삐콤씨, 안티푸라민, 렉라자, 로수바미브, 코푸시럽 등), 생활용품(유한락스...  1962-11-01  12월   \n",
       "2595  Contract Logistics, 포워딩, 항만하역, 해운, 택배국제특송, SCM...  1956-07-02  12월   \n",
       "2596          섬유류(면사,면혼방사,면직물,면혼방직물,화섬사,화섬직물) 제조,도매,수출입  1956-03-03  12월   \n",
       "2597                                               지주사업  1956-03-03  12월   \n",
       "2598                                               지주회사  1956-03-03  12월   \n",
       "\n",
       "               대표자명                                 홈페이지     지역  \n",
       "0               유근직               http://www.manyo.co.kr  서울특별시  \n",
       "1               마승철           http://www.naracellar.com/    경기도  \n",
       "2               심영수               http://www.jyp21.co.kr  인천광역시  \n",
       "3               류승호  http://www.isuspecialtychemical.com  서울특별시  \n",
       "4          김택중, 김유신                                  NaN  서울특별시  \n",
       "...             ...                                  ...    ...  \n",
       "2594       대표이사 조욱제               http://www.yuhan.co.kr  서울특별시  \n",
       "2595  강신호,민영학(각자대표)           http://www.cjlogistics.com  서울특별시  \n",
       "2596         김준, 김담           http://www.kyungbang.co.kr  서울특별시  \n",
       "2597            송영규         http://www.eusu-holdings.com  서울특별시  \n",
       "2598       조남호, 조원국         http://www.hhic-holdings.com    경기도  \n",
       "\n",
       "[2599 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "krx_list = pd.read_html('C:/Users/unbes/Downloads/상장법인목록.xls')\n",
    "krx_list[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>업종</th>\n",
       "      <th>주요제품</th>\n",
       "      <th>상장일</th>\n",
       "      <th>결산월</th>\n",
       "      <th>대표자명</th>\n",
       "      <th>홈페이지</th>\n",
       "      <th>지역</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>마녀공장</td>\n",
       "      <td>439090</td>\n",
       "      <td>기타 화학제품 제조업</td>\n",
       "      <td>자연주의 기능성 화장품</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>12월</td>\n",
       "      <td>유근직</td>\n",
       "      <td>http://www.manyo.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나라셀라</td>\n",
       "      <td>405920</td>\n",
       "      <td>음·식료품 및 담배 도매업</td>\n",
       "      <td>와인 도소매</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>12월</td>\n",
       "      <td>마승철</td>\n",
       "      <td>http://www.naracellar.com/</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>진영</td>\n",
       "      <td>285800</td>\n",
       "      <td>플라스틱제품 제조업</td>\n",
       "      <td>가구용 ASA플라스틱 시트, 엣지밴드</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>12월</td>\n",
       "      <td>심영수</td>\n",
       "      <td>http://www.jyp21.co.kr</td>\n",
       "      <td>인천광역시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이수스페셜티케미컬</td>\n",
       "      <td>457190</td>\n",
       "      <td>기초 화학물질 제조업</td>\n",
       "      <td>석유화학제품 및 정밀화학제품</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>12월</td>\n",
       "      <td>류승호</td>\n",
       "      <td>http://www.isuspecialtychemical.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCI</td>\n",
       "      <td>456040</td>\n",
       "      <td>기초 화학물질 제조업</td>\n",
       "      <td>폴리실리콘,타르제품,카본블랙,무수프탈산,농약원제,석탄화학제품,정밀화학제품,플라스틱창...</td>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>12월</td>\n",
       "      <td>김택중, 김유신</td>\n",
       "      <td>NaN</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>유한양행</td>\n",
       "      <td>000100</td>\n",
       "      <td>의약품 제조업</td>\n",
       "      <td>의약품(삐콤씨, 안티푸라민, 렉라자, 로수바미브, 코푸시럽 등), 생활용품(유한락스...</td>\n",
       "      <td>1962-11-01</td>\n",
       "      <td>12월</td>\n",
       "      <td>대표이사 조욱제</td>\n",
       "      <td>http://www.yuhan.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>000120</td>\n",
       "      <td>도로 화물 운송업</td>\n",
       "      <td>Contract Logistics, 포워딩, 항만하역, 해운, 택배국제특송, SCM...</td>\n",
       "      <td>1956-07-02</td>\n",
       "      <td>12월</td>\n",
       "      <td>강신호,민영학(각자대표)</td>\n",
       "      <td>http://www.cjlogistics.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>경방</td>\n",
       "      <td>000050</td>\n",
       "      <td>종합 소매업</td>\n",
       "      <td>섬유류(면사,면혼방사,면직물,면혼방직물,화섬사,화섬직물) 제조,도매,수출입</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>김준, 김담</td>\n",
       "      <td>http://www.kyungbang.co.kr</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>유수홀딩스</td>\n",
       "      <td>000700</td>\n",
       "      <td>회사 본부 및 경영 컨설팅 서비스업</td>\n",
       "      <td>지주사업</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>송영규</td>\n",
       "      <td>http://www.eusu-holdings.com</td>\n",
       "      <td>서울특별시</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>한진중공업홀딩스</td>\n",
       "      <td>003480</td>\n",
       "      <td>연료용 가스 제조 및 배관공급업</td>\n",
       "      <td>지주회사</td>\n",
       "      <td>1956-03-03</td>\n",
       "      <td>12월</td>\n",
       "      <td>조남호, 조원국</td>\n",
       "      <td>http://www.hhic-holdings.com</td>\n",
       "      <td>경기도</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2599 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명    종목코드                   업종   \n",
       "0          마녀공장  439090          기타 화학제품 제조업  \\\n",
       "1          나라셀라  405920       음·식료품 및 담배 도매업   \n",
       "2            진영  285800           플라스틱제품 제조업   \n",
       "3     이수스페셜티케미컬  457190          기초 화학물질 제조업   \n",
       "4           OCI  456040          기초 화학물질 제조업   \n",
       "...         ...     ...                  ...   \n",
       "2594       유한양행  000100              의약품 제조업   \n",
       "2595     CJ대한통운  000120            도로 화물 운송업   \n",
       "2596         경방  000050               종합 소매업   \n",
       "2597      유수홀딩스  000700  회사 본부 및 경영 컨설팅 서비스업   \n",
       "2598   한진중공업홀딩스  003480    연료용 가스 제조 및 배관공급업   \n",
       "\n",
       "                                                   주요제품         상장일  결산월   \n",
       "0                                          자연주의 기능성 화장품  2023-06-08  12월  \\\n",
       "1                                                와인 도소매  2023-06-02  12월   \n",
       "2                                  가구용 ASA플라스틱 시트, 엣지밴드  2023-06-01  12월   \n",
       "3                                       석유화학제품 및 정밀화학제품  2023-05-31  12월   \n",
       "4     폴리실리콘,타르제품,카본블랙,무수프탈산,농약원제,석탄화학제품,정밀화학제품,플라스틱창...  2023-05-30  12월   \n",
       "...                                                 ...         ...  ...   \n",
       "2594  의약품(삐콤씨, 안티푸라민, 렉라자, 로수바미브, 코푸시럽 등), 생활용품(유한락스...  1962-11-01  12월   \n",
       "2595  Contract Logistics, 포워딩, 항만하역, 해운, 택배국제특송, SCM...  1956-07-02  12월   \n",
       "2596          섬유류(면사,면혼방사,면직물,면혼방직물,화섬사,화섬직물) 제조,도매,수출입  1956-03-03  12월   \n",
       "2597                                               지주사업  1956-03-03  12월   \n",
       "2598                                               지주회사  1956-03-03  12월   \n",
       "\n",
       "               대표자명                                 홈페이지     지역  \n",
       "0               유근직               http://www.manyo.co.kr  서울특별시  \n",
       "1               마승철           http://www.naracellar.com/    경기도  \n",
       "2               심영수               http://www.jyp21.co.kr  인천광역시  \n",
       "3               류승호  http://www.isuspecialtychemical.com  서울특별시  \n",
       "4          김택중, 김유신                                  NaN  서울특별시  \n",
       "...             ...                                  ...    ...  \n",
       "2594       대표이사 조욱제               http://www.yuhan.co.kr  서울특별시  \n",
       "2595  강신호,민영학(각자대표)           http://www.cjlogistics.com  서울특별시  \n",
       "2596         김준, 김담           http://www.kyungbang.co.kr  서울특별시  \n",
       "2597            송영규         http://www.eusu-holdings.com  서울특별시  \n",
       "2598       조남호, 조원국         http://www.hhic-holdings.com    경기도  \n",
       "\n",
       "[2599 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krx_list[0].종목코드 = krx_list[0].종목코드.map('{:06d}'.format)\n",
    "krx_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>시장구분</td>\n",
       "      <td>전체  유가증권  코스닥  코넥스</td>\n",
       "      <td>검색유형</td>\n",
       "      <td>상장법인  관리종목  불성실공시법인  자산2조법인  외국법인  코스닥 글로벌 세그먼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>업종</td>\n",
       "      <td>전체  농업, 임업 및 어업  광업  제조업  - 식료품 제조업  - 음료 제조업 ...</td>\n",
       "      <td>결산월</td>\n",
       "      <td>전체  01월  02월  03월  04월  05월  06월  07월  08월  09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사명</td>\n",
       "      <td>찾기</td>\n",
       "      <td>지역</td>\n",
       "      <td>전체  강원도  경기도  경상남도  경상북도  광주광역시  대구광역시  대전광역시 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1     2   \n",
       "0  시장구분                                 전체  유가증권  코스닥  코넥스  검색유형  \\\n",
       "1    업종  전체  농업, 임업 및 어업  광업  제조업  - 식료품 제조업  - 음료 제조업 ...   결산월   \n",
       "2   회사명                                                 찾기    지역   \n",
       "\n",
       "                                                   3  \n",
       "0  상장법인  관리종목  불성실공시법인  자산2조법인  외국법인  코스닥 글로벌 세그먼...  \n",
       "1  전체  01월  02월  03월  04월  05월  06월  07월  08월  09...  \n",
       "2  전체  강원도  경기도  경상남도  경상북도  광주광역시  대구광역시  대전광역시 ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "df = pd.read_html('https://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage#')[0]\n",
    "# df['종목코드'] = df['종목코드'].map('{:06d}'.format)\n",
    "# df = df.sort_values(by='종목코드')\n",
    "df\n",
    "\n",
    "# df = pd.read_html('https://kind.krx.co.kr/corpList.do?method=download&searchType=13', header=0)[0]\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 웹에서 일별 시세 구하기\n",
    "네이버 금융"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 BeautifulSoup로 일별 시세 읽어오기 \n",
    "- web scrappping daily Close price via BeautifulSoup\n",
    "\n",
    "### 4.4.3 맨 뒤 페이지 숫자 구하기\n",
    "BeautifulSoup을 이용한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# 페이지 번호를 추출합니다\u001b[39;00m\n\u001b[0;32m      9\u001b[0m pagination \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39m.Nnavi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m last_page \u001b[39m=\u001b[39m pagination[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtext\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m맨 뒤 페이지 숫자:\u001b[39m\u001b[39m\"\u001b[39m, last_page)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ignore this cell\n",
    "\n",
    "import requests  # scrapping HTML code\n",
    "from bs4 import BeautifulSoup  # parsing HTML code\n",
    "\n",
    "url = \"https://finance.naver.com/item/sise_day.nhn?code=068270&page=1\"\n",
    "response = requests.get(url)  # get HTML code from url\n",
    "soup = BeautifulSoup(response.text, 'html.parser')  # parsing the HTML code\n",
    "\n",
    "# 페이지 번호를 추출합니다\n",
    "pagination = soup.select(\".Nnavi\")\n",
    "last_page = pagination[0].find_all('a')[-1].text\n",
    "\n",
    "print(\"맨 뒤 페이지 숫자:\", last_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m html \u001b[39m=\u001b[39m BeautifulSoup(doc, \u001b[39m'\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m pgrr \u001b[39m=\u001b[39m html\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpgRR\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(pgrr\u001b[39m.\u001b[39;49ma[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'\n",
    "with urlopen(url) as doc:\n",
    "    html = BeautifulSoup(doc, 'lxml')  # parsing HTML code via 'lxml' parser\n",
    "    pgrr = html.find('td', class_='pgRR')  # find our a tag 'td' / pgRR: 'PaGe Right Right'\n",
    "    print(pgrr.a['href'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this code doesn't work anymore!\n",
    "\n",
    "Instead, ChatGPT suggested this modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023.06.09, Closing Price: 169,000\n",
      "Date: 2023.06.08, Closing Price: 168,200\n",
      "Date: 2023.06.07, Closing Price: 170,400\n",
      "Date: 2023.06.05, Closing Price: 172,200\n",
      "Date: 2023.06.02, Closing Price: 173,500\n",
      "Date: 2023.06.01, Closing Price: 175,400\n",
      "Date: 2023.05.31, Closing Price: 171,300\n",
      "Date: 2023.05.30, Closing Price: 172,300\n",
      "Date: 2023.05.26, Closing Price: 173,100\n",
      "Date: 2023.05.25, Closing Price: 173,100\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_stock_price(stock_code):\n",
    "    url = f\"https://finance.naver.com/item/sise_day.nhn?code={stock_code}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find(\"table\", class_=\"type2\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 7:\n",
    "            date = columns[0].text.strip()\n",
    "            closing_price = columns[1].text.strip()\n",
    "            print(f\"Date: {date}, Closing Price: {closing_price}\")\n",
    "\n",
    "# 셀트리온의 종목 코드는 068270입니다.\n",
    "get_stock_price(\"068270\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Page: 443\n"
     ]
    }
   ],
   "source": [
    "# this is the code we're looking for\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_last_page(stock_code):\n",
    "    url = f\"https://finance.naver.com/item/sise_day.nhn?code={stock_code}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    pgrr = soup.find('td', class_='pgRR')\n",
    "    last_page_url = pgrr.a['href']\n",
    "    last_page_number = int(last_page_url.split('=')[-1])  # choose the 'last' page number\n",
    "\n",
    "    return last_page_number\n",
    "\n",
    "# 셀트리온의 종목 코드는 068270입니다.\n",
    "stock_code = \"068270\"\n",
    "last_page = get_last_page(stock_code)\n",
    "print(f\"Last Page: {last_page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/item/sise_day.nhn?code=068270&page=443', 443)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see what's in pgrr\n",
    "# just a part of the above code\n",
    "url = f\"https://finance.naver.com/item/sise_day.nhn?code={'068270'}\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "pgrr = soup.find('td', class_='pgRR')\n",
    "last_page_url = pgrr.a['href']\n",
    "last_page_number = int(last_page_url.split('=')[-1])\n",
    "\n",
    "(last_page_url, last_page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/item/sise_day.nhn?code', '068270&page', '443']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_page_url.split('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'443'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_page_url.split('=')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td class=\"pgRR\">\n",
      " <a href=\"/item/sise_day.nhn?code=068270&amp;page=443\">\n",
      "  맨뒤\n",
      "  <img alt=\"\" border=\"0\" height=\"5\" src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarRR.gif\" width=\"8\"/>\n",
      " </a>\n",
      "</td>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pgrr.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "맨뒤\n",
      "\t\t\t\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pgrr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m html \u001b[39m=\u001b[39m BeautifulSoup(doc, \u001b[39m'\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m pgrr \u001b[39m=\u001b[39m html\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpgRR\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(pgrr\u001b[39m.\u001b[39;49ma[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m last_page \u001b[39m=\u001b[39m s[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "with urlopen(url) as doc:\n",
    "    html = BeautifulSoup(doc, 'lxml')\n",
    "    pgrr = html.find('td', class_='pgRR')\n",
    "    s = str(pgrr.a['href']).split('=')\n",
    "    last_page = s[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the above inspection, this doesn't work anymore! But we succedeed to find the last page already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'443'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But this works!\n",
    "url = 'https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'\n",
    "html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text\n",
    "bs = BeautifulSoup(html, 'lxml')\n",
    "pgrr = bs.find('td', class_='pgRR')\n",
    "s = str(pgrr.a['href']).split('=')\n",
    "last_page = s[-1]\n",
    "\n",
    "last_page"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 전체 페이지 읽어오기\n",
    "\n",
    "We have scrapped data from naver_finance and could find the last_page.<br>\n",
    "Let's read the whole Close prices from the very listing day till today.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m&page=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(sise_url, page)  \n\u001b[0;32m      5\u001b[0m html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUser-agent\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mMozilla/5.0\u001b[39m\u001b[39m'\u001b[39m})\u001b[39m.\u001b[39mtext\n\u001b[1;32m----> 6\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mappend(pd\u001b[39m.\u001b[39mread_html(html, header\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# doesn't work\n",
    "df = pd.DataFrame()\n",
    "sise_url = 'https://finance.naver.com/item/sise_day.nhn?code=068270'\n",
    "\n",
    "for page in range(1, int(last_page)+1):\n",
    "    page_url = '{}&page={}'.format(sise_url, page)\n",
    "    df = pd.append(pd.read_html(page_url, header=0))\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this modification just work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            날짜        종가     전일비        시가        고가        저가       거래량\n",
      "1   2023.06.09  169000.0   800.0  168800.0  171000.0  167800.0  341714.0\n",
      "2   2023.06.08  168200.0  2200.0  170500.0  171000.0  167200.0  526815.0\n",
      "3   2023.06.07  170400.0  1800.0  172200.0  173200.0  170400.0  400233.0\n",
      "4   2023.06.05  172200.0  1300.0  174500.0  174700.0  171300.0  256488.0\n",
      "5   2023.06.02  173500.0  1900.0  176400.0  176700.0  172400.0  402399.0\n",
      "..         ...       ...     ...       ...       ...       ...       ...\n",
      "1   2005.07.25    5650.0    70.0    5500.0    5950.0    5500.0   61036.0\n",
      "2   2005.07.22    5580.0   160.0    5850.0    5850.0    5530.0   69921.0\n",
      "3   2005.07.21    5740.0   810.0    6450.0    6580.0    5730.0  182685.0\n",
      "4   2005.07.20    6550.0  1150.0    7690.0    7690.0    6550.0  422688.0\n",
      "5   2005.07.19    7700.0  2500.0    6700.0    7700.0    6510.0  499088.0\n",
      "\n",
      "[4425 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# took 27.2s\n",
    "\n",
    "df = pd.DataFrame()\n",
    "sise_url = 'https://finance.naver.com/item/sise_day.nhn?code=068270'\n",
    "\n",
    "for page in range(1, int(last_page)+1):\n",
    "    url = '{}&page={}'.format(sise_url, page)  \n",
    "    html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text\n",
    "    page_df = pd.read_html(html, header=0)[0]\n",
    "    df = pd.concat([df, page_df])\n",
    "    \n",
    "df = df.dropna()  # otherwise, there're LOTs of NaN values\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb3 in position 194: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mint\u001b[39m(last_page)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m      7\u001b[0m     page_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m&page=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(sise_url, page)\n\u001b[1;32m----> 8\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, pd\u001b[39m.\u001b[39;49mread_html(page_url, header\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[0;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m   1210\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1212\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1213\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[0;32m   1214\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[0;32m   1215\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[0;32m   1216\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m   1217\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m   1218\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m   1219\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m   1220\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m   1221\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1222\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1223\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m   1224\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m   1225\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m   1226\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m   1227\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[0;32m   1228\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[0;32m   1229\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m   1230\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:1001\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1000\u001b[0m     \u001b[39massert\u001b[39;00m retained \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[39mraise\u001b[39;00m retained\n\u001b[0;32m   1003\u001b[0m ret \u001b[39m=\u001b[39m []\n\u001b[0;32m   1004\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:981\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 981\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[0;32m    982\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[0;32m    983\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:257\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs)\n\u001b[0;32m    258\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:666\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_doc\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    664\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m--> 666\u001b[0m     bdoc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_build_doc()\n\u001b[0;32m    667\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(bdoc, \u001b[39mbytes\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m         udoc \u001b[39m=\u001b[39m bdoc\u001b[39m.\u001b[39mdecode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:658\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._setup_build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_build_doc\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 658\u001b[0m     raw_text \u001b[39m=\u001b[39m _read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mio, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding)\n\u001b[0;32m    659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_text:\n\u001b[0;32m    660\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo text parsed from document: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:156\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(obj, encoding)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    151\u001b[0m     is_url(obj)\n\u001b[0;32m    152\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m     \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(obj, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m file_exists(obj))\n\u001b[0;32m    154\u001b[0m ):\n\u001b[0;32m    155\u001b[0m     \u001b[39mwith\u001b[39;00m get_handle(obj, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39mencoding) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m--> 156\u001b[0m         text \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39;49mhandle\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    157\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m    158\u001b[0m     text \u001b[39m=\u001b[39m obj\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb3 in position 194: invalid start byte"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "sise_url = 'https://finance.naver.com/item/sise_day.nhn?code=068270'\n",
    "\n",
    "for page in range(1, int(last_page)+1):\n",
    "    page_url = '{}&page={}'.format(sise_url, page)\n",
    "    df = pd.concat([df, pd.read_html(page_url, header=0)[0]], ignore_index=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 4.4.3 맨 뒤 페이지 숫자 구하기\n",
    "url = 'https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'\n",
    "html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text\n",
    "bs = BeautifulSoup(html, 'lxml')\n",
    "pgrr = bs.find('td', class_='pgRR')\n",
    "s = str(pgrr.a['href']).split('=')\n",
    "last_page = s[-1]  \n",
    "\n",
    "# 4.4.4 전체 페이지 읽어오기\n",
    "df = pd.DataFrame()\n",
    "sise_url = 'https://finance.naver.com/item/sise_day.nhn?code=068270'  \n",
    "for page in range(1, int(last_page)+1):\n",
    "    url = '{}&page={}'.format(sise_url, page)  \n",
    "    html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text\n",
    "    df = df.append(pd.read_html(html, header=0)[0])\n",
    "\n",
    "# 차트 출력을 위해 데이터프레임 가공하기\n",
    "df = df.dropna()\n",
    "df = df.iloc[0:30]  # ①\n",
    "df = df.sort_values(by='날짜')  # ②\n",
    "\n",
    "# 날짜, 종가 컬럼으로 차트 그리기\n",
    "plt.title('Celltrion (close)')\n",
    "plt.xticks(rotation=45)  # ③\n",
    "plt.plot(df['날짜'], df['종가'], 'co-')  # ④\n",
    "plt.grid(color='gray', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 OHLC & candle chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from urllib.request import urlopen\n",
    "# from bs4 import BeautifulSoup\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Celltrion (close)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot(df['날짜'], df['종가'], 'co-')\n",
    "plt.grid(color='gray', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
